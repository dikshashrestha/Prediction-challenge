{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a203c039",
   "metadata": {},
   "source": [
    "# Kaggle ML Challenge 2 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71f527",
   "metadata": {},
   "source": [
    "**Team Members:**\n",
    "    Diksha, \n",
    "    Roshan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb150b2",
   "metadata": {},
   "source": [
    "**Introducttion:**\n",
    "\n",
    "The Getting Started Notebook is always a great help for me to get started with the Kaggle challenge. Starting with NMF and understanding the NMF pseudocode was quite challenging at first so we tried going with Multivariate Regression to see how the algorithm works and performs.\n",
    "\n",
    "Multivariate Regression can also be termed as a supervised machine learning technique. So, this explains that our model is used on the train rna and adt dataset through which we understand the relationship between them and predict the test_adt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7877a6c1",
   "metadata": {},
   "source": [
    "**Importing Dataset:**\n",
    "\n",
    "Firstly, we read the training and test csv file using the read_csv() function as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf2bf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc99b59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test_sample_1</th>\n",
       "      <th>test_sample_2</th>\n",
       "      <th>test_sample_3</th>\n",
       "      <th>test_sample_4</th>\n",
       "      <th>test_sample_5</th>\n",
       "      <th>test_sample_6</th>\n",
       "      <th>test_sample_7</th>\n",
       "      <th>test_sample_8</th>\n",
       "      <th>test_sample_9</th>\n",
       "      <th>...</th>\n",
       "      <th>test_sample_991</th>\n",
       "      <th>test_sample_992</th>\n",
       "      <th>test_sample_993</th>\n",
       "      <th>test_sample_994</th>\n",
       "      <th>test_sample_995</th>\n",
       "      <th>test_sample_996</th>\n",
       "      <th>test_sample_997</th>\n",
       "      <th>test_sample_998</th>\n",
       "      <th>test_sample_999</th>\n",
       "      <th>test_sample_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPL22</td>\n",
       "      <td>2.500262</td>\n",
       "      <td>2.900439</td>\n",
       "      <td>2.953532</td>\n",
       "      <td>2.999922</td>\n",
       "      <td>3.181827</td>\n",
       "      <td>3.267155</td>\n",
       "      <td>2.899259</td>\n",
       "      <td>3.157958</td>\n",
       "      <td>2.942404</td>\n",
       "      <td>...</td>\n",
       "      <td>1.879607</td>\n",
       "      <td>1.560418</td>\n",
       "      <td>3.692494</td>\n",
       "      <td>2.745812</td>\n",
       "      <td>3.154371</td>\n",
       "      <td>3.595094</td>\n",
       "      <td>2.925132</td>\n",
       "      <td>3.116989</td>\n",
       "      <td>4.084811</td>\n",
       "      <td>3.827927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARK7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.572109</td>\n",
       "      <td>0.997105</td>\n",
       "      <td>1.424210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.705567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.928458</td>\n",
       "      <td>1.969240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENO1</td>\n",
       "      <td>2.877991</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>1.185308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.702991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.389076</td>\n",
       "      <td>1.767994</td>\n",
       "      <td>1.555977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.593159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RBP7</td>\n",
       "      <td>1.885984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.942404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.085065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGTRAP</td>\n",
       "      <td>1.885984</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.371941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.593159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  test_sample_1  test_sample_2  test_sample_3  test_sample_4  \\\n",
       "0      RPL22       2.500262       2.900439       2.953532       2.999922   \n",
       "1      PARK7       0.000000       1.351622       0.000000       1.572109   \n",
       "2       ENO1       2.877991       1.351622       1.185308       0.000000   \n",
       "3       RBP7       1.885984       0.000000       0.000000       0.000000   \n",
       "4     AGTRAP       1.885984       1.351622       0.000000       0.000000   \n",
       "\n",
       "   test_sample_5  test_sample_6  test_sample_7  test_sample_8  test_sample_9  \\\n",
       "0       3.181827       3.267155       2.899259       3.157958       2.942404   \n",
       "1       0.997105       1.424210       0.000000       1.705567       0.000000   \n",
       "2       0.617999       0.000000       0.000000       0.000000       1.702991   \n",
       "3       0.000000       0.000000       0.000000       0.000000       2.942404   \n",
       "4       0.000000       0.000000       0.000000       0.000000       0.000000   \n",
       "\n",
       "   ...  test_sample_991  test_sample_992  test_sample_993  test_sample_994  \\\n",
       "0  ...         1.879607         1.560418         3.692494         2.745812   \n",
       "1  ...         1.328524         0.000000         0.000000         0.000000   \n",
       "2  ...         0.000000         0.000000         1.389076         1.767994   \n",
       "3  ...         0.000000         0.000000         0.000000         0.000000   \n",
       "4  ...         0.000000         0.000000         0.000000         2.371941   \n",
       "\n",
       "   test_sample_995  test_sample_996  test_sample_997  test_sample_998  \\\n",
       "0         3.154371         3.595094         2.925132         3.116989   \n",
       "1         0.000000         0.000000         1.928458         1.969240   \n",
       "2         1.555977         0.000000         1.593159         0.000000   \n",
       "3         0.000000         0.000000         1.085065         0.000000   \n",
       "4         0.000000         0.000000         1.593159         0.000000   \n",
       "\n",
       "   test_sample_999  test_sample_1000  \n",
       "0         4.084811          3.827927  \n",
       "1         0.000000          0.000000  \n",
       "2         0.000000          0.000000  \n",
       "3         0.000000          0.000000  \n",
       "4         0.000000          0.000000  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rna = pd.read_csv('test_set_rna.csv')\n",
    "test_rna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f8017dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>training_sample_1</th>\n",
       "      <th>training_sample_2</th>\n",
       "      <th>training_sample_3</th>\n",
       "      <th>training_sample_4</th>\n",
       "      <th>training_sample_5</th>\n",
       "      <th>training_sample_6</th>\n",
       "      <th>training_sample_7</th>\n",
       "      <th>training_sample_8</th>\n",
       "      <th>training_sample_9</th>\n",
       "      <th>...</th>\n",
       "      <th>training_sample_3991</th>\n",
       "      <th>training_sample_3992</th>\n",
       "      <th>training_sample_3993</th>\n",
       "      <th>training_sample_3994</th>\n",
       "      <th>training_sample_3995</th>\n",
       "      <th>training_sample_3996</th>\n",
       "      <th>training_sample_3997</th>\n",
       "      <th>training_sample_3998</th>\n",
       "      <th>training_sample_3999</th>\n",
       "      <th>training_sample_4000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CD11a</td>\n",
       "      <td>0.413866</td>\n",
       "      <td>0.294449</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.263649</td>\n",
       "      <td>0.438042</td>\n",
       "      <td>0.686346</td>\n",
       "      <td>0.730096</td>\n",
       "      <td>0.299949</td>\n",
       "      <td>1.111089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526016</td>\n",
       "      <td>1.348110</td>\n",
       "      <td>0.512804</td>\n",
       "      <td>0.408960</td>\n",
       "      <td>1.166204</td>\n",
       "      <td>0.713007</td>\n",
       "      <td>0.368821</td>\n",
       "      <td>1.064956</td>\n",
       "      <td>1.060479</td>\n",
       "      <td>0.808950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD11c</td>\n",
       "      <td>1.299088</td>\n",
       "      <td>0.136347</td>\n",
       "      <td>1.043159</td>\n",
       "      <td>0.246849</td>\n",
       "      <td>0.284185</td>\n",
       "      <td>0.404868</td>\n",
       "      <td>0.603104</td>\n",
       "      <td>0.354919</td>\n",
       "      <td>0.482943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512543</td>\n",
       "      <td>0.490426</td>\n",
       "      <td>0.371848</td>\n",
       "      <td>0.320178</td>\n",
       "      <td>2.240665</td>\n",
       "      <td>0.609743</td>\n",
       "      <td>0.217903</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.475405</td>\n",
       "      <td>0.371848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CD123</td>\n",
       "      <td>0.474643</td>\n",
       "      <td>0.205216</td>\n",
       "      <td>0.520798</td>\n",
       "      <td>0.073185</td>\n",
       "      <td>0.265222</td>\n",
       "      <td>0.564916</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.321830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607170</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.375404</td>\n",
       "      <td>0.724171</td>\n",
       "      <td>1.967158</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.073185</td>\n",
       "      <td>1.714842</td>\n",
       "      <td>0.686671</td>\n",
       "      <td>0.265222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CD127-IL7Ra</td>\n",
       "      <td>0.402731</td>\n",
       "      <td>0.757762</td>\n",
       "      <td>0.354215</td>\n",
       "      <td>0.872654</td>\n",
       "      <td>1.337662</td>\n",
       "      <td>1.864847</td>\n",
       "      <td>0.615251</td>\n",
       "      <td>0.984558</td>\n",
       "      <td>0.303224</td>\n",
       "      <td>...</td>\n",
       "      <td>1.124305</td>\n",
       "      <td>0.320511</td>\n",
       "      <td>1.764897</td>\n",
       "      <td>0.303224</td>\n",
       "      <td>0.386819</td>\n",
       "      <td>1.796728</td>\n",
       "      <td>1.191072</td>\n",
       "      <td>0.249493</td>\n",
       "      <td>2.544464</td>\n",
       "      <td>1.850105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CD14</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>0.160274</td>\n",
       "      <td>0.298374</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>0.272238</td>\n",
       "      <td>0.419696</td>\n",
       "      <td>0.587582</td>\n",
       "      <td>0.323845</td>\n",
       "      <td>0.272238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396581</td>\n",
       "      <td>0.396581</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>0.323845</td>\n",
       "      <td>2.448333</td>\n",
       "      <td>0.606716</td>\n",
       "      <td>0.160274</td>\n",
       "      <td>1.459272</td>\n",
       "      <td>0.625492</td>\n",
       "      <td>0.507158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  training_sample_1  training_sample_2  training_sample_3  \\\n",
       "0        CD11a           0.413866           0.294449           0.531469   \n",
       "1        CD11c           1.299088           0.136347           1.043159   \n",
       "2        CD123           0.474643           0.205216           0.520798   \n",
       "3  CD127-IL7Ra           0.402731           0.757762           0.354215   \n",
       "4         CD14           0.527878           0.160274           0.298374   \n",
       "\n",
       "   training_sample_4  training_sample_5  training_sample_6  training_sample_7  \\\n",
       "0           0.263649           0.438042           0.686346           0.730096   \n",
       "1           0.246849           0.284185           0.404868           0.603104   \n",
       "2           0.073185           0.265222           0.564916           0.426254   \n",
       "3           0.872654           1.337662           1.864847           0.615251   \n",
       "4           0.189462           0.272238           0.419696           0.587582   \n",
       "\n",
       "   training_sample_8  training_sample_9  ...  training_sample_3991  \\\n",
       "0           0.299949           1.111089  ...              0.526016   \n",
       "1           0.354919           0.482943  ...              0.512543   \n",
       "2           0.426254           0.321830  ...              0.607170   \n",
       "3           0.984558           0.303224  ...              1.124305   \n",
       "4           0.323845           0.272238  ...              0.396581   \n",
       "\n",
       "   training_sample_3992  training_sample_3993  training_sample_3994  \\\n",
       "0              1.348110              0.512804              0.408960   \n",
       "1              0.490426              0.371848              0.320178   \n",
       "2              0.426254              0.375404              0.724171   \n",
       "3              0.320511              1.764897              0.303224   \n",
       "4              0.396581              0.527878              0.323845   \n",
       "\n",
       "   training_sample_3995  training_sample_3996  training_sample_3997  \\\n",
       "0              1.166204              0.713007              0.368821   \n",
       "1              2.240665              0.609743              0.217903   \n",
       "2              1.967158              0.426254              0.073185   \n",
       "3              0.386819              1.796728              1.191072   \n",
       "4              2.448333              0.606716              0.160274   \n",
       "\n",
       "   training_sample_3998  training_sample_3999  training_sample_4000  \n",
       "0              1.064956              1.060479              0.808950  \n",
       "1              0.880499              0.475405              0.371848  \n",
       "2              1.714842              0.686671              0.265222  \n",
       "3              0.249493              2.544464              1.850105  \n",
       "4              1.459272              0.625492              0.507158  \n",
       "\n",
       "[5 rows x 4001 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_adt = pd.read_csv('training_set_adt.csv')\n",
    "training_adt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1604642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>training_sample_1</th>\n",
       "      <th>training_sample_2</th>\n",
       "      <th>training_sample_3</th>\n",
       "      <th>training_sample_4</th>\n",
       "      <th>training_sample_5</th>\n",
       "      <th>training_sample_6</th>\n",
       "      <th>training_sample_7</th>\n",
       "      <th>training_sample_8</th>\n",
       "      <th>training_sample_9</th>\n",
       "      <th>...</th>\n",
       "      <th>training_sample_3991</th>\n",
       "      <th>training_sample_3992</th>\n",
       "      <th>training_sample_3993</th>\n",
       "      <th>training_sample_3994</th>\n",
       "      <th>training_sample_3995</th>\n",
       "      <th>training_sample_3996</th>\n",
       "      <th>training_sample_3997</th>\n",
       "      <th>training_sample_3998</th>\n",
       "      <th>training_sample_3999</th>\n",
       "      <th>training_sample_4000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPL22</td>\n",
       "      <td>1.946768</td>\n",
       "      <td>2.993597</td>\n",
       "      <td>2.327345</td>\n",
       "      <td>3.355145</td>\n",
       "      <td>2.992697</td>\n",
       "      <td>3.409415</td>\n",
       "      <td>3.241927</td>\n",
       "      <td>3.219029</td>\n",
       "      <td>2.797789</td>\n",
       "      <td>...</td>\n",
       "      <td>2.791541</td>\n",
       "      <td>2.979010</td>\n",
       "      <td>3.776064</td>\n",
       "      <td>1.593003</td>\n",
       "      <td>3.770663</td>\n",
       "      <td>2.535107</td>\n",
       "      <td>3.322802</td>\n",
       "      <td>2.018552</td>\n",
       "      <td>3.790125</td>\n",
       "      <td>3.059502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARK7</td>\n",
       "      <td>1.387045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.727283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.814190</td>\n",
       "      <td>...</td>\n",
       "      <td>1.808623</td>\n",
       "      <td>1.977239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.362115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.151552</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENO1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.747344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.297154</td>\n",
       "      <td>1.013754</td>\n",
       "      <td>1.757990</td>\n",
       "      <td>1.814190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.660966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.018552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.622036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RBP7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGTRAP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  training_sample_1  training_sample_2  training_sample_3  \\\n",
       "0      RPL22           1.946768           2.993597           2.327345   \n",
       "1      PARK7           1.387045           0.000000           1.727283   \n",
       "2       ENO1           0.000000           1.747344           0.000000   \n",
       "3       RBP7           0.000000           0.000000           0.000000   \n",
       "4     AGTRAP           0.000000           0.000000           0.000000   \n",
       "\n",
       "   training_sample_4  training_sample_5  training_sample_6  training_sample_7  \\\n",
       "0           3.355145           2.992697           3.409415           3.241927   \n",
       "1           0.000000           0.000000           0.000000           1.013754   \n",
       "2           0.000000           0.000000           1.297154           1.013754   \n",
       "3           0.000000           0.000000           0.000000           0.000000   \n",
       "4           0.000000           0.000000           0.000000           1.013754   \n",
       "\n",
       "   training_sample_8  training_sample_9  ...  training_sample_3991  \\\n",
       "0           3.219029           2.797789  ...              2.791541   \n",
       "1           0.000000           1.814190  ...              1.808623   \n",
       "2           1.757990           1.814190  ...              0.000000   \n",
       "3           0.000000           0.000000  ...              0.000000   \n",
       "4           0.000000           0.000000  ...              0.000000   \n",
       "\n",
       "   training_sample_3992  training_sample_3993  training_sample_3994  \\\n",
       "0              2.979010              3.776064              1.593003   \n",
       "1              1.977239              0.000000              0.000000   \n",
       "2              0.000000              1.660966              0.000000   \n",
       "3              0.000000              0.000000              0.000000   \n",
       "4              0.000000              0.000000              0.000000   \n",
       "\n",
       "   training_sample_3995  training_sample_3996  training_sample_3997  \\\n",
       "0              3.770663              2.535107              3.322802   \n",
       "1              0.000000              1.362115              0.000000   \n",
       "2              0.000000              0.000000              0.000000   \n",
       "3              0.000000              0.000000              0.000000   \n",
       "4              0.000000              0.000000              0.000000   \n",
       "\n",
       "   training_sample_3998  training_sample_3999  training_sample_4000  \n",
       "0              2.018552              3.790125              3.059502  \n",
       "1              0.000000              1.151552              0.000000  \n",
       "2              2.018552              0.000000              1.622036  \n",
       "3              0.000000              0.000000              0.000000  \n",
       "4              0.000000              0.000000              0.000000  \n",
       "\n",
       "[5 rows x 4001 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_rna = pd.read_csv(\"training_set_rna.csv\")\n",
    "training_rna.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba14f2",
   "metadata": {},
   "source": [
    "I then proceeded with dropping the first column from all the dataset to proceed with the matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ff43154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_sample_1</th>\n",
       "      <th>test_sample_2</th>\n",
       "      <th>test_sample_3</th>\n",
       "      <th>test_sample_4</th>\n",
       "      <th>test_sample_5</th>\n",
       "      <th>test_sample_6</th>\n",
       "      <th>test_sample_7</th>\n",
       "      <th>test_sample_8</th>\n",
       "      <th>test_sample_9</th>\n",
       "      <th>test_sample_10</th>\n",
       "      <th>...</th>\n",
       "      <th>test_sample_991</th>\n",
       "      <th>test_sample_992</th>\n",
       "      <th>test_sample_993</th>\n",
       "      <th>test_sample_994</th>\n",
       "      <th>test_sample_995</th>\n",
       "      <th>test_sample_996</th>\n",
       "      <th>test_sample_997</th>\n",
       "      <th>test_sample_998</th>\n",
       "      <th>test_sample_999</th>\n",
       "      <th>test_sample_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.500262</td>\n",
       "      <td>2.900439</td>\n",
       "      <td>2.953532</td>\n",
       "      <td>2.999922</td>\n",
       "      <td>3.181827</td>\n",
       "      <td>3.267155</td>\n",
       "      <td>2.899259</td>\n",
       "      <td>3.157958</td>\n",
       "      <td>2.942404</td>\n",
       "      <td>2.670896</td>\n",
       "      <td>...</td>\n",
       "      <td>1.879607</td>\n",
       "      <td>1.560418</td>\n",
       "      <td>3.692494</td>\n",
       "      <td>2.745812</td>\n",
       "      <td>3.154371</td>\n",
       "      <td>3.595094</td>\n",
       "      <td>2.925132</td>\n",
       "      <td>3.116989</td>\n",
       "      <td>4.084811</td>\n",
       "      <td>3.827927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.572109</td>\n",
       "      <td>0.997105</td>\n",
       "      <td>1.424210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.705567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.701890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.928458</td>\n",
       "      <td>1.969240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.877991</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>1.185308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.702991</td>\n",
       "      <td>2.299441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.389076</td>\n",
       "      <td>1.767994</td>\n",
       "      <td>1.555977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.593159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.885984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.942404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.085065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.885984</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.371941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.593159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_sample_1  test_sample_2  test_sample_3  test_sample_4  test_sample_5  \\\n",
       "0       2.500262       2.900439       2.953532       2.999922       3.181827   \n",
       "1       0.000000       1.351622       0.000000       1.572109       0.997105   \n",
       "2       2.877991       1.351622       1.185308       0.000000       0.617999   \n",
       "3       1.885984       0.000000       0.000000       0.000000       0.000000   \n",
       "4       1.885984       1.351622       0.000000       0.000000       0.000000   \n",
       "\n",
       "   test_sample_6  test_sample_7  test_sample_8  test_sample_9  test_sample_10  \\\n",
       "0       3.267155       2.899259       3.157958       2.942404        2.670896   \n",
       "1       1.424210       0.000000       1.705567       0.000000        1.701890   \n",
       "2       0.000000       0.000000       0.000000       1.702991        2.299441   \n",
       "3       0.000000       0.000000       0.000000       2.942404        0.000000   \n",
       "4       0.000000       0.000000       0.000000       0.000000        0.000000   \n",
       "\n",
       "   ...  test_sample_991  test_sample_992  test_sample_993  test_sample_994  \\\n",
       "0  ...         1.879607         1.560418         3.692494         2.745812   \n",
       "1  ...         1.328524         0.000000         0.000000         0.000000   \n",
       "2  ...         0.000000         0.000000         1.389076         1.767994   \n",
       "3  ...         0.000000         0.000000         0.000000         0.000000   \n",
       "4  ...         0.000000         0.000000         0.000000         2.371941   \n",
       "\n",
       "   test_sample_995  test_sample_996  test_sample_997  test_sample_998  \\\n",
       "0         3.154371         3.595094         2.925132         3.116989   \n",
       "1         0.000000         0.000000         1.928458         1.969240   \n",
       "2         1.555977         0.000000         1.593159         0.000000   \n",
       "3         0.000000         0.000000         1.085065         0.000000   \n",
       "4         0.000000         0.000000         1.593159         0.000000   \n",
       "\n",
       "   test_sample_999  test_sample_1000  \n",
       "0         4.084811          3.827927  \n",
       "1         0.000000          0.000000  \n",
       "2         0.000000          0.000000  \n",
       "3         0.000000          0.000000  \n",
       "4         0.000000          0.000000  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_test_rna = test_rna.drop(test_rna.columns[0], axis =1)\n",
    "update_test_rna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c60058a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_sample_1</th>\n",
       "      <th>training_sample_2</th>\n",
       "      <th>training_sample_3</th>\n",
       "      <th>training_sample_4</th>\n",
       "      <th>training_sample_5</th>\n",
       "      <th>training_sample_6</th>\n",
       "      <th>training_sample_7</th>\n",
       "      <th>training_sample_8</th>\n",
       "      <th>training_sample_9</th>\n",
       "      <th>training_sample_10</th>\n",
       "      <th>...</th>\n",
       "      <th>training_sample_3991</th>\n",
       "      <th>training_sample_3992</th>\n",
       "      <th>training_sample_3993</th>\n",
       "      <th>training_sample_3994</th>\n",
       "      <th>training_sample_3995</th>\n",
       "      <th>training_sample_3996</th>\n",
       "      <th>training_sample_3997</th>\n",
       "      <th>training_sample_3998</th>\n",
       "      <th>training_sample_3999</th>\n",
       "      <th>training_sample_4000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.413866</td>\n",
       "      <td>0.294449</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.263649</td>\n",
       "      <td>0.438042</td>\n",
       "      <td>0.686346</td>\n",
       "      <td>0.730096</td>\n",
       "      <td>0.299949</td>\n",
       "      <td>1.111089</td>\n",
       "      <td>0.272143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526016</td>\n",
       "      <td>1.348110</td>\n",
       "      <td>0.512804</td>\n",
       "      <td>0.408960</td>\n",
       "      <td>1.166204</td>\n",
       "      <td>0.713007</td>\n",
       "      <td>0.368821</td>\n",
       "      <td>1.064956</td>\n",
       "      <td>1.060479</td>\n",
       "      <td>0.808950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.299088</td>\n",
       "      <td>0.136347</td>\n",
       "      <td>1.043159</td>\n",
       "      <td>0.246849</td>\n",
       "      <td>0.284185</td>\n",
       "      <td>0.404868</td>\n",
       "      <td>0.603104</td>\n",
       "      <td>0.354919</td>\n",
       "      <td>0.482943</td>\n",
       "      <td>0.198129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512543</td>\n",
       "      <td>0.490426</td>\n",
       "      <td>0.371848</td>\n",
       "      <td>0.320178</td>\n",
       "      <td>2.240665</td>\n",
       "      <td>0.609743</td>\n",
       "      <td>0.217903</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.475405</td>\n",
       "      <td>0.371848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474643</td>\n",
       "      <td>0.205216</td>\n",
       "      <td>0.520798</td>\n",
       "      <td>0.073185</td>\n",
       "      <td>0.265222</td>\n",
       "      <td>0.564916</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.321830</td>\n",
       "      <td>0.265222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607170</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.375404</td>\n",
       "      <td>0.724171</td>\n",
       "      <td>1.967158</td>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.073185</td>\n",
       "      <td>1.714842</td>\n",
       "      <td>0.686671</td>\n",
       "      <td>0.265222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402731</td>\n",
       "      <td>0.757762</td>\n",
       "      <td>0.354215</td>\n",
       "      <td>0.872654</td>\n",
       "      <td>1.337662</td>\n",
       "      <td>1.864847</td>\n",
       "      <td>0.615251</td>\n",
       "      <td>0.984558</td>\n",
       "      <td>0.303224</td>\n",
       "      <td>0.911364</td>\n",
       "      <td>...</td>\n",
       "      <td>1.124305</td>\n",
       "      <td>0.320511</td>\n",
       "      <td>1.764897</td>\n",
       "      <td>0.303224</td>\n",
       "      <td>0.386819</td>\n",
       "      <td>1.796728</td>\n",
       "      <td>1.191072</td>\n",
       "      <td>0.249493</td>\n",
       "      <td>2.544464</td>\n",
       "      <td>1.850105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.527878</td>\n",
       "      <td>0.160274</td>\n",
       "      <td>0.298374</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>0.272238</td>\n",
       "      <td>0.419696</td>\n",
       "      <td>0.587582</td>\n",
       "      <td>0.323845</td>\n",
       "      <td>0.272238</td>\n",
       "      <td>0.160274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396581</td>\n",
       "      <td>0.396581</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>0.323845</td>\n",
       "      <td>2.448333</td>\n",
       "      <td>0.606716</td>\n",
       "      <td>0.160274</td>\n",
       "      <td>1.459272</td>\n",
       "      <td>0.625492</td>\n",
       "      <td>0.507158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_sample_1  training_sample_2  training_sample_3  training_sample_4  \\\n",
       "0           0.413866           0.294449           0.531469           0.263649   \n",
       "1           1.299088           0.136347           1.043159           0.246849   \n",
       "2           0.474643           0.205216           0.520798           0.073185   \n",
       "3           0.402731           0.757762           0.354215           0.872654   \n",
       "4           0.527878           0.160274           0.298374           0.189462   \n",
       "\n",
       "   training_sample_5  training_sample_6  training_sample_7  training_sample_8  \\\n",
       "0           0.438042           0.686346           0.730096           0.299949   \n",
       "1           0.284185           0.404868           0.603104           0.354919   \n",
       "2           0.265222           0.564916           0.426254           0.426254   \n",
       "3           1.337662           1.864847           0.615251           0.984558   \n",
       "4           0.272238           0.419696           0.587582           0.323845   \n",
       "\n",
       "   training_sample_9  training_sample_10  ...  training_sample_3991  \\\n",
       "0           1.111089            0.272143  ...              0.526016   \n",
       "1           0.482943            0.198129  ...              0.512543   \n",
       "2           0.321830            0.265222  ...              0.607170   \n",
       "3           0.303224            0.911364  ...              1.124305   \n",
       "4           0.272238            0.160274  ...              0.396581   \n",
       "\n",
       "   training_sample_3992  training_sample_3993  training_sample_3994  \\\n",
       "0              1.348110              0.512804              0.408960   \n",
       "1              0.490426              0.371848              0.320178   \n",
       "2              0.426254              0.375404              0.724171   \n",
       "3              0.320511              1.764897              0.303224   \n",
       "4              0.396581              0.527878              0.323845   \n",
       "\n",
       "   training_sample_3995  training_sample_3996  training_sample_3997  \\\n",
       "0              1.166204              0.713007              0.368821   \n",
       "1              2.240665              0.609743              0.217903   \n",
       "2              1.967158              0.426254              0.073185   \n",
       "3              0.386819              1.796728              1.191072   \n",
       "4              2.448333              0.606716              0.160274   \n",
       "\n",
       "   training_sample_3998  training_sample_3999  training_sample_4000  \n",
       "0              1.064956              1.060479              0.808950  \n",
       "1              0.880499              0.475405              0.371848  \n",
       "2              1.714842              0.686671              0.265222  \n",
       "3              0.249493              2.544464              1.850105  \n",
       "4              1.459272              0.625492              0.507158  \n",
       "\n",
       "[5 rows x 4000 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_training_adt = training_adt.drop(training_adt.columns[0], axis =1)\n",
    "update_training_adt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a15b1dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_sample_1</th>\n",
       "      <th>training_sample_2</th>\n",
       "      <th>training_sample_3</th>\n",
       "      <th>training_sample_4</th>\n",
       "      <th>training_sample_5</th>\n",
       "      <th>training_sample_6</th>\n",
       "      <th>training_sample_7</th>\n",
       "      <th>training_sample_8</th>\n",
       "      <th>training_sample_9</th>\n",
       "      <th>training_sample_10</th>\n",
       "      <th>...</th>\n",
       "      <th>training_sample_3991</th>\n",
       "      <th>training_sample_3992</th>\n",
       "      <th>training_sample_3993</th>\n",
       "      <th>training_sample_3994</th>\n",
       "      <th>training_sample_3995</th>\n",
       "      <th>training_sample_3996</th>\n",
       "      <th>training_sample_3997</th>\n",
       "      <th>training_sample_3998</th>\n",
       "      <th>training_sample_3999</th>\n",
       "      <th>training_sample_4000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.946768</td>\n",
       "      <td>2.993597</td>\n",
       "      <td>2.327345</td>\n",
       "      <td>3.355145</td>\n",
       "      <td>2.992697</td>\n",
       "      <td>3.409415</td>\n",
       "      <td>3.241927</td>\n",
       "      <td>3.219029</td>\n",
       "      <td>2.797789</td>\n",
       "      <td>3.629944</td>\n",
       "      <td>...</td>\n",
       "      <td>2.791541</td>\n",
       "      <td>2.979010</td>\n",
       "      <td>3.776064</td>\n",
       "      <td>1.593003</td>\n",
       "      <td>3.770663</td>\n",
       "      <td>2.535107</td>\n",
       "      <td>3.322802</td>\n",
       "      <td>2.018552</td>\n",
       "      <td>3.790125</td>\n",
       "      <td>3.059502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.387045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.727283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.814190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.808623</td>\n",
       "      <td>1.977239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.362115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.151552</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.747344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.297154</td>\n",
       "      <td>1.013754</td>\n",
       "      <td>1.757990</td>\n",
       "      <td>1.814190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.660966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.018552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.622036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_sample_1  training_sample_2  training_sample_3  training_sample_4  \\\n",
       "0           1.946768           2.993597           2.327345           3.355145   \n",
       "1           1.387045           0.000000           1.727283           0.000000   \n",
       "2           0.000000           1.747344           0.000000           0.000000   \n",
       "3           0.000000           0.000000           0.000000           0.000000   \n",
       "4           0.000000           0.000000           0.000000           0.000000   \n",
       "\n",
       "   training_sample_5  training_sample_6  training_sample_7  training_sample_8  \\\n",
       "0           2.992697           3.409415           3.241927           3.219029   \n",
       "1           0.000000           0.000000           1.013754           0.000000   \n",
       "2           0.000000           1.297154           1.013754           1.757990   \n",
       "3           0.000000           0.000000           0.000000           0.000000   \n",
       "4           0.000000           0.000000           1.013754           0.000000   \n",
       "\n",
       "   training_sample_9  training_sample_10  ...  training_sample_3991  \\\n",
       "0           2.797789            3.629944  ...              2.791541   \n",
       "1           1.814190            0.000000  ...              1.808623   \n",
       "2           1.814190            0.000000  ...              0.000000   \n",
       "3           0.000000            0.000000  ...              0.000000   \n",
       "4           0.000000            0.000000  ...              0.000000   \n",
       "\n",
       "   training_sample_3992  training_sample_3993  training_sample_3994  \\\n",
       "0              2.979010              3.776064              1.593003   \n",
       "1              1.977239              0.000000              0.000000   \n",
       "2              0.000000              1.660966              0.000000   \n",
       "3              0.000000              0.000000              0.000000   \n",
       "4              0.000000              0.000000              0.000000   \n",
       "\n",
       "   training_sample_3995  training_sample_3996  training_sample_3997  \\\n",
       "0              3.770663              2.535107              3.322802   \n",
       "1              0.000000              1.362115              0.000000   \n",
       "2              0.000000              0.000000              0.000000   \n",
       "3              0.000000              0.000000              0.000000   \n",
       "4              0.000000              0.000000              0.000000   \n",
       "\n",
       "   training_sample_3998  training_sample_3999  training_sample_4000  \n",
       "0              2.018552              3.790125              3.059502  \n",
       "1              0.000000              1.151552              0.000000  \n",
       "2              2.018552              0.000000              1.622036  \n",
       "3              0.000000              0.000000              0.000000  \n",
       "4              0.000000              0.000000              0.000000  \n",
       "\n",
       "[5 rows x 4000 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_training_rna = training_rna.drop(training_rna.columns[0], axis = 1)\n",
    "update_training_rna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c415d90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 1000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the dataframe into array\n",
    "testrna_array = update_test_rna.values\n",
    "testrna_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b24b2129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingadt_array = update_training_adt.values\n",
    "trainingadt_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8772c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 4000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingrna_array = update_training_rna.values\n",
    "trainingrna_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635dfa77",
   "metadata": {},
   "source": [
    "**Multivariate Regression**\n",
    "\n",
    "We use the multivariate regression technique, Ax= y to model the relationship between the train_rna and train_adt. We used gradient descent optimization algorithm to find x and once we had obtained x, we mapped x into the new dataset test_rna to predict the cooresponding values of test_adt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d69da609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 4000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting A as train_\n",
    "A = trainingrna_array\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cb89c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting y as train_adt\n",
    "y = trainingadt_array\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41cf285e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 639)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting it in the form of ax=b through transposing and matrix multiplication\n",
    "a = np.dot(A,A.T)\n",
    "a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7ac4498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 25)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.dot(A,y.T)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7bb65",
   "metadata": {},
   "source": [
    "We then used gradient descent to find the x. **Gradient Descent** is an iterative optimization algorithm used to find the minimum of the function.\n",
    "\n",
    "Our gd_solve function takes the parameter a, b which we get from our above code. The gd_solve also takes the parameter max_iter which states the maximum iteration, and tol_cutoff states the tolerance level at which the algorithm will stop.\n",
    "\n",
    "Our function first sets x as array of zeros with the same dimension as b. Our x is updated through running in the loop until the maximum iteration is achieved. As our loop starts, it will execute 639 times going for each row of the array and will calculate the ith row of b dividing by the ith row of the diagonal a which then updates the solution x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b0fce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying gradient descent algorithm to find the value of x\n",
    "\n",
    "def gd_solve(a, b, max_iter=100, tol_cutoff=1e-15):\n",
    "    x = np.zeros_like(b)\n",
    "    for iter in range(1, max_iter+1):\n",
    "        tol = np.zeros_like(b)\n",
    "#         print(tol.shape)\n",
    "        #print(len(b))\n",
    "        for i in range(len(b)):\n",
    "            #print(b[i])\n",
    "            #print(a[i,i])\n",
    "            z = b[i] / a[i, i]\n",
    "            x[i] += z\n",
    "            b -= z * a[:, i].reshape((len(b), 1))\n",
    "            tol += np.abs(z / x[i])\n",
    "        if np.all(tol < tol_cutoff):\n",
    "            print('Break')\n",
    "            break\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "x2 = gd_solve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98570c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 25)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd9ae8",
   "metadata": {},
   "source": [
    "We tried to see if our above function worked for predicting the test_adt and followed the below steps to predict the test_adt using our test_rna dataset. After saving the submisson folder, we then changed on converting our submission file to Kaggle submission format in the R from the code provided by the Professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e93a0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 25)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transposing the test_rna and finding the dot product of test_rna and x2\n",
    "ytest = np.dot(testrna_array.T,x2)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75f184a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest1=ytest.T\n",
    "ytest1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a859d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('submission.csv', ytest1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fbed8",
   "metadata": {},
   "source": [
    "From our first Kaggle submission, our Pearson Correlation Coefficient score was **0.80178** which was above the good score from the evaluation. So, we knew that we were on right track and started tweaking with our Multivariate Regression code to see how it can perform better. We firstly started with changing the maximum iteration and tolerance cutoff which increased our score to **0.80217**. In the meantime, we both started working on understanding the NMF algorithm and started researching and trying on both of our ends.\n",
    "\n",
    "We also tried Gaussian Elimination to see how it works, but our score was relatively same performing the Gaussian Elimination. After researching more, we came across about learning rate and tried implementing learning rate in our Multivariate Regression code.\n",
    "\n",
    "**Learning Rate** is a hyperparameter that controls the step size at which the model's parameters are updated during training. So, through learning rate, we know how much parameters of the model are adjusted in response to the estimated error at each iteration of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ea7cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_solve(a, b, learning_rate = 0.001, max_iter=100, tol_cutoff=1e-15):\n",
    "    x = np.zeros_like(b)\n",
    "    for iter in range(1, max_iter+1):\n",
    "        tol = np.zeros_like(b)\n",
    "        for i in range(len(b)):\n",
    "            #print(b[i])\n",
    "            z = b[i] / a[i, i]\n",
    "            x[i] += learning_rate * z\n",
    "            b -= learning_rate * z * a[:, i].reshape((len(b), 1))\n",
    "            tol += np.abs(z / x[i])\n",
    "        if np.all(tol < tol_cutoff):\n",
    "            print('Break')\n",
    "            break\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "x2 = gd_solve(a, b, learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ca5770b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 25)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de1f4b",
   "metadata": {},
   "source": [
    "Implementing the learning rate in our gradient descent algorithm, our score increased to **0.80235**. We then started tweaking with the learning rate to find our optimal learning rate and we found our optimal learning rate was at 0.0001 which increased our score to **0.81240**. We also tried implementing regularization but it was not suitable for our algorithm. So, we then started tweaking with maximum iteration and tolerance cutoff to see if we could achieve the cutoff point. After many try, we found our maximum iteration as 18000 which provided a high score of **0.81440**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05729b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 25)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transposing the test_rna and finding the dot product of test_rna and x2\n",
    "ytest = np.dot(testrna_array.T,x2)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "554282d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest1=ytest.T\n",
    "ytest1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d1de555",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('submission.csv', ytest1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b783216",
   "metadata": {},
   "source": [
    "After downloading our submission.csv file, we then referred back to R studio to convert the submission file into Kaggle submission format by reshaping them from wide to tall following below code in R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac83f8",
   "metadata": {},
   "source": [
    "\n",
    "Convert to Kaggle submission format by reshaping from wide to tall:\n",
    "```{r}\n",
    "test <- as.matrix(read.csv(\"submission.csv\", row.names = 1))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```{R}\n",
    "sample_submission <- reshape2::melt(test)\n",
    "head(sample_submission)\n",
    "```\n",
    "\n",
    "```{R}\n",
    "sample_submission <- data.frame(\n",
    "  \"ID\" = paste0(\"ID_\", 1:nrow(sample_submission)), \n",
    "  \"Expected\" = sample_submission$value)\n",
    "head(sample_submission)\n",
    "```\n",
    "\n",
    "Write the final submission file.\n",
    "\n",
    "```{R}\n",
    "write.csv(sample_submission, \"my_submission.csv\", row.names = FALSE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b663d4",
   "metadata": {},
   "source": [
    "**Other Approach Implementation:**\n",
    "\n",
    "**NMF Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce0622",
   "metadata": {},
   "source": [
    "Non-negative Matrix Factorization is one of the dimension reduction technique that is used to find the approximate value as of the original matrix when we multiply the W and H matrices.\n",
    "\n",
    "We then use gradient descent first to find out the value for x. The gradient descent for the Multivariate Regression and NMF is different as it includes non-negativity in the gradient descent. The non-negativity constraint can lead the factorization to be more interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33d5f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that performs gradient descent \n",
    "\n",
    "def gd_solve(a, b, max_iter=100, tol_cutoff=1e-8):\n",
    "    x = np.zeros(len(b))\n",
    "    for iter in range(1, max_iter+1):\n",
    "        tol = 0\n",
    "        for i in range(len(b)):\n",
    "            if a[i, i] == 0:\n",
    "                z = 0\n",
    "            else:\n",
    "                z = b[i] / a[i, i]\n",
    "            \n",
    "            if x[i] + z < 0:\n",
    "                z = -x[i]\n",
    "                x[i]=0\n",
    "            else:    \n",
    "                x[i] = x[i] + z\n",
    "            \n",
    "            b = b - z * a[:, i]\n",
    "            tol = tol + abs(z / (x[i] + 1e-15))\n",
    "        if tol < tol_cutoff:\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd32ad1",
   "metadata": {},
   "source": [
    "We then worked on creating the function for the NMF from the pseudocode. Firstly, W is randomly intialized and we set H as all zero. First on each iteration, the function updates H from A and ranomly intialized W by soliving the linear system of equations. The NMF function uses the gd_solve function(gradient descent algorithm) to solve it. Once, we have found H, the function then updates W matrix using the linear system of equation. To calculate the W matrix, it also uses the gd_solve(gradient descent) algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d378590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that performs NMF\n",
    "\n",
    "def nmf(A, k, max_iter=10):\n",
    "    # Initialize W randomly and set H as 0\n",
    "    m, n = A.shape\n",
    "    W = abs(np.random.rand(m, k))\n",
    "    H = np.zeros((k, n))\n",
    "    at=A.T\n",
    "\n",
    "    # Iteratively update W and H\n",
    "    for i in range(max_iter):\n",
    "        # Update H\n",
    "        a = np.dot(W.T, W)\n",
    "        #print('a',a.shape)\n",
    "        for j in range(n):\n",
    "            \n",
    "            b = np.dot(W.T, A[:, j])\n",
    "            x= gd_solve(a,b)\n",
    "            H[:,j] = x\n",
    "       \n",
    "        \n",
    "        # Update W\n",
    "        aw = np.dot(H,H.T)\n",
    "        #print('aw is: ',aw.shape)\n",
    "        for i in range(0,m):\n",
    "            bw = np.dot(H, at[:,i])\n",
    "            #print('bw is: ',bw.shape)\n",
    "            x1= gd_solve(aw,bw)\n",
    "            W.T[:, i] = x1\n",
    "        \n",
    " \n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3e3dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "w1,h1=nmf(A,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecd42043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5b6a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4000)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1\n",
    "h1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69bf78",
   "metadata": {},
   "source": [
    "We first tried to see if our NMF algorithm was implemented and tried to see if we faced any errors. We were mostly focused on implementing the pseudocode, so we didn't focus on scaling W and H due to the time limitation as we were also working on tweaking the Multivariate Regression. Firstly, we tried working with k =2 to see how our NMF model was accurate trying to visualize it using the scatterplot. Also, we tried implementing k as 3 and 15 where 15 provided more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1206a",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "We tried working with Multivariate Regression which provided a good score, however, we also wanted to try NMF to predict and see how it performs and compare both the models. Unfortunately, with limited time, we couldn't complete implementing NMF model as we were yet to work on scaling the W and H matrix then mask the train_adt to predict it. We also want to work on implementing NMF during our Spring Break to see how it performs and compare both the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee331b",
   "metadata": {},
   "source": [
    "**Reference**:\n",
    "1. https://www.mygreatlearning.com/blog/understanding-learning-rate-in-machine-learning/#:~:text=Learning%20rate%20is%20used%20to,function%20is%20minimized%20or%20not.\n",
    "2. https://blog.acolyer.org/2019/02/18/the-why-and-how-of-nonnegative-matrix-factorization/#:~:text=Nonnegative%20matrix%20factorization%20(NMF)%20has,Lee%20and%20Seung%20in%201999.\n",
    "3. https://www.kaggle.com/code/zdebruine/getting-started-with-ml-challenge-2-prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
